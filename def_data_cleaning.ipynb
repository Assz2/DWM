{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Cleaning Workflow** \n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Import Already Filtered Data**  \n",
    "- Drop records where:  \n",
    "   - **`'sii'`** is `NaN`.  \n",
    "- Save it as target variables:  \n",
    "   - ðŸŽ¯ **`sii`**  \n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Feature Cleaning**  \n",
    "-  Drop all **features** that are present **only in the train set**.  \n",
    "-  Remove features where **`NaN` values â‰¥ 50%** (Threshold: **`0.5`**).  \n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Dataset Splitting**  \n",
    "- **Split the dataset** into:  \n",
    "   -  **Numerical Features**  \n",
    "   -  **Categorical Features**\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Feature Engineering**\n",
    "-  Train a **Random Forest** to apply a subselection of the features. We will have only the `most informative features`\n",
    "-  Train a **New Random Forest** and exploit the similarity score to fill out `missing values` through a process of **`missing value imputation`** \n",
    "    and ensure the result matches the feature type:  Truncate **float** to **integer** where needed.\n",
    "-  Merge all **FGC-Zone features**:  \n",
    "   - Compute: **`feature + (zone_feature * 0.25(feature))`**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **5. Categorical Feature Encoding**  \n",
    "- Use **1-Hot Encoding (OHE)**:  \n",
    "   -  `pd.get_dummies()`\n",
    "\n",
    "---\n",
    "\n",
    "#### **6. Handle Outliers (Optional)**  \n",
    "- ðŸš¨ **[EVENTUALLY]**: Remove records with extremely **high values**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **7. Correlation Check (Optional)**  \n",
    "-  ðŸš¨ **[EVENTUALLY]**: Compute the **correlation matrix** and if extremely high `(positive or negative)` correlation is found:\n",
    "   - Create a `new dataset` without the least informative features with strongest correlation\n",
    "\n",
    "---\n",
    "\n",
    "#### **8. Export Dataset**  \n",
    "- **Export the two different dataset**.  \n",
    "- Proceed to:  \n",
    "   - Find out what dataset between the two exported has **better performances**\n",
    "   - Build **four classification models**.  \n",
    "   - Perform **hyperparameter tuning**.  \n",
    "   - Document appropriate **considerations**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1. Import Already Filtered Data**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is kind of strange and after lot of tries I can firmly say it have a lot of outliers. \n",
    "# Studying the dataset I found three specific incredibly high and strange values and I decided to remove them by hand. \n",
    "# This is why the name of this step is called \"Already Filtered\".\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "TRAIN_SET = os.getenv(\"FILTERED_TRAIN_PATH\")\n",
    "TEST_SET  = os.getenv(\"TEST_PATH\")\n",
    "\n",
    "train = pd.read_csv(TRAIN_SET)\n",
    "test = pd.read_csv(TEST_SET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>PCIAT-PCIAT_18</th>\n",
       "      <th>PCIAT-PCIAT_19</th>\n",
       "      <th>PCIAT-PCIAT_20</th>\n",
       "      <th>PCIAT-PCIAT_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0  00008ff9                      Fall                5                0   \n",
       "1  000fd460                    Summer                9                0   \n",
       "2  00105258                    Summer               10                1   \n",
       "3  00115b9f                    Winter                9                0   \n",
       "4  0016bb22                    Spring               18                1   \n",
       "\n",
       "  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0      Winter             51.0            Fall     16.877316             46.0   \n",
       "1         NaN              NaN            Fall     14.035590             48.0   \n",
       "2        Fall             71.0            Fall     16.648696             56.5   \n",
       "3        Fall             71.0          Summer     18.292347             56.0   \n",
       "4      Summer              NaN             NaN           NaN              NaN   \n",
       "\n",
       "   Physical-Weight  ...  PCIAT-PCIAT_18  PCIAT-PCIAT_19  PCIAT-PCIAT_20  \\\n",
       "0             50.8  ...             4.0             2.0             4.0   \n",
       "1             46.0  ...             0.0             0.0             0.0   \n",
       "2             75.6  ...             2.0             1.0             1.0   \n",
       "3             81.6  ...             3.0             4.0             1.0   \n",
       "4              NaN  ...             NaN             NaN             NaN   \n",
       "\n",
       "   PCIAT-PCIAT_Total SDS-Season  SDS-SDS_Total_Raw  SDS-SDS_Total_T  \\\n",
       "0               55.0        NaN                NaN              NaN   \n",
       "1                0.0       Fall               46.0             64.0   \n",
       "2               28.0       Fall               38.0             54.0   \n",
       "3               44.0     Summer               31.0             45.0   \n",
       "4                NaN        NaN                NaN              NaN   \n",
       "\n",
       "   PreInt_EduHx-Season PreInt_EduHx-computerinternet_hoursday  sii  \n",
       "0                 Fall                                    3.0  2.0  \n",
       "1               Summer                                    0.0  0.0  \n",
       "2               Summer                                    2.0  0.0  \n",
       "3               Winter                                    0.0  1.0  \n",
       "4                  NaN                                    NaN  NaN  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>...</th>\n",
       "      <th>BIA-BIA_TBW</th>\n",
       "      <th>PAQ_A-Season</th>\n",
       "      <th>PAQ_A-PAQ_A_Total</th>\n",
       "      <th>PAQ_C-Season</th>\n",
       "      <th>PAQ_C-PAQ_C_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>...</td>\n",
       "      <td>32.6909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2.340</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.170</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>...</td>\n",
       "      <td>45.9966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.451</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n",
       "0  00008ff9                      Fall                5                0   \n",
       "1  000fd460                    Summer                9                0   \n",
       "2  00105258                    Summer               10                1   \n",
       "3  00115b9f                    Winter                9                0   \n",
       "4  0016bb22                    Spring               18                1   \n",
       "\n",
       "  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0      Winter             51.0            Fall     16.877316             46.0   \n",
       "1         NaN              NaN            Fall     14.035590             48.0   \n",
       "2        Fall             71.0            Fall     16.648696             56.5   \n",
       "3        Fall             71.0          Summer     18.292347             56.0   \n",
       "4      Summer              NaN             NaN           NaN              NaN   \n",
       "\n",
       "   Physical-Weight  ...  BIA-BIA_TBW  PAQ_A-Season  PAQ_A-PAQ_A_Total  \\\n",
       "0             50.8  ...      32.6909           NaN                NaN   \n",
       "1             46.0  ...      27.0552           NaN                NaN   \n",
       "2             75.6  ...          NaN           NaN                NaN   \n",
       "3             81.6  ...      45.9966           NaN                NaN   \n",
       "4              NaN  ...          NaN        Summer               1.04   \n",
       "\n",
       "   PAQ_C-Season PAQ_C-PAQ_C_Total  SDS-Season  SDS-SDS_Total_Raw  \\\n",
       "0           NaN               NaN         NaN                NaN   \n",
       "1          Fall             2.340        Fall               46.0   \n",
       "2        Summer             2.170        Fall               38.0   \n",
       "3        Winter             2.451      Summer               31.0   \n",
       "4           NaN               NaN         NaN                NaN   \n",
       "\n",
       "   SDS-SDS_Total_T PreInt_EduHx-Season  PreInt_EduHx-computerinternet_hoursday  \n",
       "0              NaN                Fall                                     3.0  \n",
       "1             64.0              Summer                                     0.0  \n",
       "2             54.0              Summer                                     2.0  \n",
       "3             45.0              Winter                                     0.0  \n",
       "4              NaN                 NaN                                     NaN  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove records with 'sii' value NaN\n",
    "x_train = train.dropna(subset=['sii'])\n",
    "\n",
    "# Extract 'sii' (target variable) \n",
    "y_train = x_train['sii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'id' from both train and test:\n",
    "x_train = x_train.drop(columns=['id'])\n",
    "x_train = x_train.drop(columns=['sii'])\n",
    "\n",
    "x_test = test.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2733, 80), (2733,))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 58)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### **2. Feature Cleaning**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITION\n",
    "\n",
    "# given the train dataset, drop the features only present in the train dataset\n",
    "def intersect_features(train, test):\n",
    "    features = train[train.columns.intersection(test.columns)]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2733, 58), (2733,))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = intersect_features(x_train, x_test)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION DEFINITION\n",
    "\n",
    "# drop all the features that have an arbitrary % threshold of missing values\n",
    "def drop_columns(df, threshold):\n",
    "    min_count = len(df) * threshold\n",
    "    dropped_cols = df.columns[df.isnull().sum() > (len(df) - min_count)]\n",
    "    df = df.drop(columns=dropped_cols)\n",
    "    return df, dropped_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Physical-Waist_Circumference', 'Fitness_Endurance-Season',\n",
       "       'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins',\n",
       "       'Fitness_Endurance-Time_Sec', 'FGC-FGC_GSND', 'FGC-FGC_GSND_Zone',\n",
       "       'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, dropped_cols = drop_columns(x_train, 0.5)\n",
    "dropped_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2733, 47), (2733,))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### **3. Data Splitting**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features: Index(['Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-CGAS_Score', 'Physical-BMI',\n",
      "       'Physical-Height', 'Physical-Weight', 'Physical-Diastolic_BP',\n",
      "       'Physical-HeartRate', 'Physical-Systolic_BP', 'FGC-FGC_CU',\n",
      "       'FGC-FGC_CU_Zone', 'FGC-FGC_PU', 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL',\n",
      "       'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR', 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL',\n",
      "       'FGC-FGC_TL_Zone', 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC',\n",
      "       'BIA-BIA_BMI', 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW',\n",
      "       'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat',\n",
      "       'BIA-BIA_Frame_num', 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST',\n",
      "       'BIA-BIA_SMM', 'BIA-BIA_TBW', 'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
      "       'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'],\n",
      "      dtype='object')\n",
      "\n",
      "Categorical features: Index(['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season',\n",
      "       'FGC-Season', 'BIA-Season', 'PAQ_C-Season', 'SDS-Season',\n",
      "       'PreInt_EduHx-Season'],\n",
      "      dtype='object')\n",
      "\n",
      " Numerical dataset shape: (2733, 39); Categorical dataset shape: (2733, 8)\n"
     ]
    }
   ],
   "source": [
    "# split numerical and categorical features\n",
    "num_features = x_train.select_dtypes(include=[np.number]).columns\n",
    "cat_features = x_train.select_dtypes(include=[object]).columns\n",
    "\n",
    "print(f'Numerical features: {num_features}')\n",
    "print(f'\\nCategorical features: {cat_features}')\n",
    "print(f'\\n Numerical dataset shape: {x_train[num_features].shape}; Categorical dataset shape: {x_train[cat_features].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### **4. Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step -> look at confusion matrix and drop columns with extremely high correlation if present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second step -> missing value imputation through a Regressor for numerical (float64) features. First try is fully grown trees with 20 iterations for the imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (2733, 37)\n",
      "[IterativeImputer] Ending imputation round 1/20, elapsed time 17.22\n",
      "[IterativeImputer] Change: 171.12939451799653, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 2/20, elapsed time 36.21\n",
      "[IterativeImputer] Change: 192.40956948888913, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 3/20, elapsed time 55.18\n",
      "[IterativeImputer] Change: 155.53965038066636, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 4/20, elapsed time 73.65\n",
      "[IterativeImputer] Change: 141.3296961333334, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 5/20, elapsed time 92.32\n",
      "[IterativeImputer] Change: 120.33330133333214, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 6/20, elapsed time 111.66\n",
      "[IterativeImputer] Change: 127.12785133333315, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 7/20, elapsed time 131.59\n",
      "[IterativeImputer] Change: 110.88522882222173, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 8/20, elapsed time 151.89\n",
      "[IterativeImputer] Change: 127.33740086666646, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 9/20, elapsed time 173.16\n",
      "[IterativeImputer] Change: 122.20747288888876, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 10/20, elapsed time 196.89\n",
      "[IterativeImputer] Change: 125.56945266666635, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 11/20, elapsed time 217.34\n",
      "[IterativeImputer] Change: 110.1312793333336, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 12/20, elapsed time 237.43\n",
      "[IterativeImputer] Change: 123.65526620000097, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 13/20, elapsed time 258.94\n",
      "[IterativeImputer] Change: 119.26202999999946, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 14/20, elapsed time 280.41\n",
      "[IterativeImputer] Change: 94.10183784444526, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 15/20, elapsed time 302.49\n",
      "[IterativeImputer] Change: 126.9216857555565, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 16/20, elapsed time 325.75\n",
      "[IterativeImputer] Change: 118.21618866666684, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 17/20, elapsed time 350.04\n",
      "[IterativeImputer] Change: 126.21294622222192, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 18/20, elapsed time 375.74\n",
      "[IterativeImputer] Change: 44.92578577777714, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 19/20, elapsed time 401.84\n",
      "[IterativeImputer] Change: 90.08489724444485, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Ending imputation round 20/20, elapsed time 429.81\n",
      "[IterativeImputer] Change: 123.9578526666682, scaled tolerance: 7.99408 \n",
      "[IterativeImputer] Completing matrix with shape (2733, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:895: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Ending imputation round 1/20, elapsed time 2.52\n",
      "[IterativeImputer] Ending imputation round 2/20, elapsed time 5.21\n",
      "[IterativeImputer] Ending imputation round 3/20, elapsed time 8.20\n",
      "[IterativeImputer] Ending imputation round 4/20, elapsed time 10.64\n",
      "[IterativeImputer] Ending imputation round 5/20, elapsed time 13.07\n",
      "[IterativeImputer] Ending imputation round 6/20, elapsed time 16.30\n",
      "[IterativeImputer] Ending imputation round 7/20, elapsed time 18.83\n",
      "[IterativeImputer] Ending imputation round 8/20, elapsed time 21.74\n",
      "[IterativeImputer] Ending imputation round 9/20, elapsed time 24.61\n",
      "[IterativeImputer] Ending imputation round 10/20, elapsed time 27.54\n",
      "[IterativeImputer] Ending imputation round 11/20, elapsed time 30.55\n",
      "[IterativeImputer] Ending imputation round 12/20, elapsed time 32.94\n",
      "[IterativeImputer] Ending imputation round 13/20, elapsed time 36.12\n",
      "[IterativeImputer] Ending imputation round 14/20, elapsed time 39.18\n",
      "[IterativeImputer] Ending imputation round 15/20, elapsed time 42.72\n",
      "[IterativeImputer] Ending imputation round 16/20, elapsed time 46.00\n",
      "[IterativeImputer] Ending imputation round 17/20, elapsed time 48.62\n",
      "[IterativeImputer] Ending imputation round 18/20, elapsed time 51.18\n",
      "[IterativeImputer] Ending imputation round 19/20, elapsed time 53.73\n",
      "[IterativeImputer] Ending imputation round 20/20, elapsed time 56.97\n"
     ]
    }
   ],
   "source": [
    "# train a Random Forest to fill the missing values based on similarity scores\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer # scikit-learn tool to fill in (impute) missing values in the dataset\n",
    "\n",
    "imp = IterativeImputer(estimator=RandomForestRegressor(\n",
    "    n_estimators=45,\n",
    "    random_state=0,\n",
    "    n_jobs=-1\n",
    "    ), max_iter=20, verbose=2, random_state=0)\n",
    "# estimator -> we specify the model to use and predict the missing values\n",
    "# max_iter -> the number of iterations for the imputer to refine its estimates\n",
    "\n",
    "# fit the imputer on the train dataset, I only fill the float64 features\n",
    "imp.fit(x_train[num_features.drop('Basic_Demos-Age').drop('Basic_Demos-Sex')])\n",
    "x_train[num_features.drop('Basic_Demos-Age').drop('Basic_Demos-Sex')] = imp.transform(x_train[num_features.drop('Basic_Demos-Age').drop('Basic_Demos-Sex')])\n",
    "# transform -> uses the learned relationships to fill in the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad results. Let's try with simpler models (knn or bayesian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If anything works, try deleting extreme outliers (99percentile of some features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2733 entries, 0 to 3955\n",
      "Data columns (total 47 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Basic_Demos-Enroll_Season               2733 non-null   object \n",
      " 1   Basic_Demos-Age                         2733 non-null   int64  \n",
      " 2   Basic_Demos-Sex                         2733 non-null   int64  \n",
      " 3   CGAS-Season                             2339 non-null   object \n",
      " 4   CGAS-CGAS_Score                         2733 non-null   float64\n",
      " 5   Physical-Season                         2592 non-null   object \n",
      " 6   Physical-BMI                            2733 non-null   float64\n",
      " 7   Physical-Height                         2733 non-null   float64\n",
      " 8   Physical-Weight                         2733 non-null   float64\n",
      " 9   Physical-Diastolic_BP                   2733 non-null   float64\n",
      " 10  Physical-HeartRate                      2733 non-null   float64\n",
      " 11  Physical-Systolic_BP                    2733 non-null   float64\n",
      " 12  FGC-Season                              2644 non-null   object \n",
      " 13  FGC-FGC_CU                              2733 non-null   float64\n",
      " 14  FGC-FGC_CU_Zone                         2733 non-null   float64\n",
      " 15  FGC-FGC_PU                              2733 non-null   float64\n",
      " 16  FGC-FGC_PU_Zone                         2733 non-null   float64\n",
      " 17  FGC-FGC_SRL                             2733 non-null   float64\n",
      " 18  FGC-FGC_SRL_Zone                        2733 non-null   float64\n",
      " 19  FGC-FGC_SRR                             2733 non-null   float64\n",
      " 20  FGC-FGC_SRR_Zone                        2733 non-null   float64\n",
      " 21  FGC-FGC_TL                              2733 non-null   float64\n",
      " 22  FGC-FGC_TL_Zone                         2733 non-null   float64\n",
      " 23  BIA-Season                              1841 non-null   object \n",
      " 24  BIA-BIA_Activity_Level_num              2733 non-null   float64\n",
      " 25  BIA-BIA_BMC                             2733 non-null   float64\n",
      " 26  BIA-BIA_BMI                             2733 non-null   float64\n",
      " 27  BIA-BIA_BMR                             2733 non-null   float64\n",
      " 28  BIA-BIA_DEE                             2733 non-null   float64\n",
      " 29  BIA-BIA_ECW                             2733 non-null   float64\n",
      " 30  BIA-BIA_FFM                             2733 non-null   float64\n",
      " 31  BIA-BIA_FFMI                            2733 non-null   float64\n",
      " 32  BIA-BIA_FMI                             2733 non-null   float64\n",
      " 33  BIA-BIA_Fat                             2733 non-null   float64\n",
      " 34  BIA-BIA_Frame_num                       2733 non-null   float64\n",
      " 35  BIA-BIA_ICW                             2733 non-null   float64\n",
      " 36  BIA-BIA_LDM                             2733 non-null   float64\n",
      " 37  BIA-BIA_LST                             2733 non-null   float64\n",
      " 38  BIA-BIA_SMM                             2733 non-null   float64\n",
      " 39  BIA-BIA_TBW                             2733 non-null   float64\n",
      " 40  PAQ_C-Season                            1437 non-null   object \n",
      " 41  PAQ_C-PAQ_C_Total                       2733 non-null   float64\n",
      " 42  SDS-Season                              2524 non-null   object \n",
      " 43  SDS-SDS_Total_Raw                       2733 non-null   float64\n",
      " 44  SDS-SDS_Total_T                         2733 non-null   float64\n",
      " 45  PreInt_EduHx-Season                     2716 non-null   object \n",
      " 46  PreInt_EduHx-computerinternet_hoursday  2733 non-null   float64\n",
      "dtypes: float64(37), int64(2), object(8)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 2733 entries, 0 to 3955\n",
      "Series name: sii\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "2733 non-null   float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 42.7 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Fall'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7340\\231616243.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train a Random Forest to subselect the most important features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# Validate or convert input data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         X, y = validate_data(\n\u001b[0m\u001b[0;32m    361\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2957\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2958\u001b[0m                 \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2960\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2961\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2964\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1052\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 raise ValueError(\n\u001b[0;32m   1058\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alesz\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Fall'"
     ]
    }
   ],
   "source": [
    "# train a Random Forest to subselect the most important features\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(x_train.fillna(0), y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
